Machine Unlearning em Modelos Supervisionados no Contexto da LGPD
âš ï¸ Projeto em desenvolvimento â€“ este repositÃ³rio estÃ¡ sendo atualizado continuamente conforme o progresso da pesquisa.

Este projeto explora tÃ©cnicas de machine unlearning com foco na conformidade com a LGPD (Lei Geral de ProteÃ§Ã£o de Dados), Ã©tica em IA e eficiÃªncia computacional. A proposta busca garantir o direito ao esquecimento, permitindo a remoÃ§Ã£o de dados especÃ­ficos de modelos treinados sem a necessidade de retrain completo.

ğŸ” Objetivo
Comparar estratÃ©gias de unlearning em tarefas de classificaÃ§Ã£o de texto (detecÃ§Ã£o de discurso de Ã³dio), avaliando impacto em desempenho, explicabilidade e viabilidade tÃ©cnica.

âš™ï¸ Tecnologias e Modelos Utilizados:
Python, scikit-learn, pandas, matplotlib

Random Forest: modelo base explicÃ¡vel e simbÃ³lico

SISA (Sharded, Isolated, Sliced, and Aggregated training): benchmark robusto

BERT (baseline NLP)

DaRE-RF: tentativa de uso da biblioteca oficial e desenvolvimento de versÃ£o simplificada

Tree-Based Selective Forgetting: abordagem prÃ³pria com poda seletiva para unlearning eficiente e explicÃ¡vel

ğŸ“Š Metodologia:
SimulaÃ§Ã£o de pedidos de exclusÃ£o de dados com base no dataset HateBR

AvaliaÃ§Ã£o das tÃ©cnicas quanto ao:

ğŸ”¹ Custo computacional

ğŸ”¹ Fidelidade do esquecimento

ğŸ”¹ ManutenÃ§Ã£o de mÃ©tricas (acurÃ¡cia, F1-score, precisÃ£o, recall)

ğŸ”¹ Explicabilidade e rastreabilidade

ğŸ“Œ Destaques:
ImplementaÃ§Ã£o de unlearning sem retrain completo em modelos baseados em Ã¡rvore

Alinhamento com regulamentaÃ§Ãµes de privacidade e princÃ­pios de IA Ã©tica

ContribuiÃ§Ã£o ativa em pesquisa aplicada com potencial de publicaÃ§Ã£o cientÃ­fica

ğŸ“ Este repositÃ³rio serÃ¡ atualizado conforme o avanÃ§o da implementaÃ§Ã£o, testes e documentaÃ§Ã£o.
